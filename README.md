# Project descriptions

## MNIST_softmax.ipynb:
Implementation of Batch Gradient Descent and Mini-Batch Gradient Descent for Softmax only using numpy functionality (scikit learn used only for loading the data and splitting it into train and test sets)

## backprop.ipynb:
Implementation of the back propagation algorithm for an arbitrary (fully connected) MLP with Softmax. Training on MNIST

## tensorflow-MLP-ipynb:
Implementation of computational graphs in TensorFlow by using only "low-level" functions of TensorFlow

## MNIST-MLP_keras.ipynb:
Train and evaluate a Multi-Layer Perceptron on the MNIST dataset. Implementaton with Keras

## CIFAR10-MLP_keras.ipynb:
Train and evaluate a Multi-Layer Perceptron on the CIFAR10 dataset. Implementaton with Keras

## CIFAR10-CNN_keras.ipynb:
Train and evaluate a CNN on the CIFAR10 dataset. Implementaton with Keras

## CIFAR10-CNN_data_aug_visual.ipynb:
CNN trained and evaluated on CIFAR10 with augmented dataset and visualization of activations. Implementation with Keras.

## transfer_learning_CIFAR10.ipynb:
Transfer learning implementation with Keras, trained on CIFAR10.

## notMNIST-auto-encoder.ipynb:
Implementation of a shallow dense auto-encoder with Keras on notMNIST data set
